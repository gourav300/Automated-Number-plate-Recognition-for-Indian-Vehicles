{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ddca24b-56ac-4a70-8fae-ddedcdb3e9b7",
   "metadata": {},
   "source": [
    "## Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7a2c98-993b-45be-a2a1-3f93d9cd514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93ac946c-6af2-4bb6-9942-49fd0c28c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model files and paths\n",
    "files = {\n",
    "    \"pipeline_config_ssd\" : os.path.join('eported_models','ssd_mobilnet_numberplate_region_detection','pipeline.config'),\n",
    "    \"label_map_ssd\" : os.path.join('eported_models','ssd_mobilnet_numberplate_region_detection','label_map.pbtxt'),\n",
    "    \"pipeline_config_efficientdet\" : os.path.join('eported_models','efficientdet_d0_ocr_numberplate','pipeline.config'),\n",
    "    \"label_map_efficientdet\" : os.path.join('eported_models','efficientdet_d0_ocr_numberplate','label_map.pbtxt')\n",
    "}\n",
    "paths = {\n",
    "    \"checkpoint_path_ssd\" : os.path.join('eported_models','ssd_mobilnet_numberplate_region_detection','checkpoint'),\n",
    "    \"checkpoint_path_efficientdet\" : os.path.join('eported_models','efficientdet_d0_ocr_numberplate','checkpoint')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0b7ed94-188e-4a03-a850-7542c17cd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model for number plate region detection\n",
    "configs_ssd = config_util.get_configs_from_pipeline_file(files['pipeline_config_ssd'])\n",
    "detection_model_ssd = model_builder.build(model_config=configs_ssd['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt_ssd = tf.compat.v2.train.Checkpoint(model=detection_model_ssd)\n",
    "ckpt_ssd.restore(os.path.join(paths['checkpoint_path_ssd'], 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn_ssd(image):\n",
    "    image, shapes = detection_model_ssd.preprocess(image)\n",
    "    prediction_dict = detection_model_ssd.predict(image, shapes)\n",
    "    detections = detection_model_ssd.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0821aea1-0cff-4acc-91c9-d6e018ff8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model for ocr\n",
    "configs_efficientdet = config_util.get_configs_from_pipeline_file(files['pipeline_config_efficientdet'])\n",
    "detection_model_efficientdet = model_builder.build(model_config=configs_efficientdet['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt_efficientdet = tf.compat.v2.train.Checkpoint(model=detection_model_efficientdet)\n",
    "ckpt_efficientdet.restore(os.path.join(paths['checkpoint_path_efficientdet'], 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn_efficientdet(image):\n",
    "    image, shapes = detection_model_efficientdet.preprocess(image)\n",
    "    prediction_dict = detection_model_efficientdet.predict(image, shapes)\n",
    "    detections = detection_model_efficientdet.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f2de491d-10be-451c-96d6-b40ac1b5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import uuid\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "885b4c39-3207-4098-8c7b-9364df02afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns= ['vehicle_number','day','date','time'])\n",
    "# df.to_csv(\"vehicle_number_plate_record.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4abc583-1a35-49b6-bd56-b84a10291443",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index_ssd = label_map_util.create_category_index_from_labelmap(files['label_map_ssd'])\n",
    "category_index_efficientdet = label_map_util.create_category_index_from_labelmap(files['label_map_efficientdet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "980c3f27-0a54-4efc-9284-db63517327e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.join('Tensorflow', 'workspace','images', 'test', 'iwt425.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8de77527-979c-40f6-b763-98c4f262977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize_with_padding(image):\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    old_size = image.shape[:2] # old_size is in (height, width) format\n",
    "    \n",
    "    if max(old_size) > 256:\n",
    "        desired_size = 512\n",
    "    else:\n",
    "        desired_size = 256\n",
    "        \n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, (new_size[1],new_size[0]))\n",
    "\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    # print(top,bottom,left,right)\n",
    "\n",
    "    color = [255, 255, 255]\n",
    "    new_im = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    \n",
    "    return new_im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "42030b8c-819f-4479-93cc-033ee0d04f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_predict(img,threshold):\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   \n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn_efficientdet(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    image_np_with_detections = cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index_efficientdet,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=12,\n",
    "                min_score_thresh=threshold,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    # print(detections)\n",
    "    #get data(label, xmin, ymin, xmax, ymax)\n",
    "\n",
    "    output = []\n",
    "    for index, score in enumerate(detections['detection_scores']):\n",
    "        if score < threshold:\n",
    "            continue\n",
    "        label = category_index[detections['detection_classes'][index] + label_id_offset]['name']\n",
    "        # print(label)\n",
    "        ymin, xmin, ymax, xmax = detections['detection_boxes'][index]\n",
    "        output.append((label, int(xmin * image_width), int(ymin * image_height),\n",
    "                       int(xmax * image_width), int(ymax * image_height)))\n",
    "\n",
    "    df = pd.DataFrame(output, columns = ['label','xmin','ymin','xmax','ymax'])\n",
    "    # df = df.sort_values(by = ['xmin','ymin'])\n",
    "    df_up = df[df.ymin < (df.ymin.min()*1.2)].sort_values(by  = ['xmin'])\n",
    "    df_down = df[df.ymin > (df.ymin.min()*1.2)].sort_values(by  = ['xmin'])\n",
    "    df = pd.concat([df_up,df_down])\n",
    "    vehicle_number = \"\".join(df[\"label\"])\n",
    "    \n",
    "    vehicle_data = pd.read_csv(\"vehicle_number_plate_record.csv\")\n",
    "    \n",
    "    current_date_time = datetime.datetime.now()\n",
    "    day = current_date_time.strftime(\"%A\")\n",
    "    date = current_date_time.strftime(\"%d/%m/%Y\")\n",
    "    time = current_date_time.strftime(\"%I:%M:%S %p\")\n",
    "    data = [(vehicle_number,day,date,time)]\n",
    "    # print(data)\n",
    "    vehicle_df = pd.DataFrame(data, columns = ['vehicle_number','day','date','time'])\n",
    "    vehicle_data = pd.concat([vehicle_data,vehicle_df], ignore_index=True)\n",
    "    \n",
    "    vehicle_data.to_csv(\"vehicle_number_plate_record.csv\",index=False)\n",
    "    \n",
    "    \n",
    "    print(vehicle_number)\n",
    "    \n",
    "    # save incident \n",
    "#     for l, x_min, y_min, x_max, y_max in output:\n",
    "\n",
    "#         # if l == \"NumberPlate\": #label_to_look_for\n",
    "#         array = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "#         image = Image.fromarray(array)\n",
    "\n",
    "    # imgname = os.path.join('output_images',f'{str(uuid.uuid1())}.jpg')\n",
    "    # to save full images with bounding boxes\n",
    "    # image_np_with_detections.save(imgname, 'JPEG', icc_profile=image_np_with_detections.info.get('icc_profile'))\n",
    "    if len(vehicle_number) == 0:\n",
    "        cv2.imwrite(os.path.join('output_images',f'{str(uuid.uuid1())}.jpg'), image_np_with_detections)\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join('output_images',f'{vehicle_number}.jpg'), image_np_with_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3a9be6e7-ce26-4e62-a64f-b7913de68943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(folder_path,threshold):\n",
    "    \n",
    "    file_list = [file for file in os.listdir(folder_path) \n",
    "         if os.path.isfile(os.path.join(folder_path, file))]\n",
    "    \n",
    "    jpg_list = []\n",
    "    substring = '.jpg'\n",
    "    jpg_list = [string for string in file_list if substring in string]\n",
    "    for jpg in jpg_list:\n",
    "        \n",
    "        img = cv2.imread(os.path.join(folder_path,jpg))\n",
    "        image_height = img.shape[0]\n",
    "        image_width = img.shape[1]\n",
    "        image_np = np.array(img)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn_ssd(input_tensor)\n",
    "\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                      for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np_with_detections,\n",
    "                    detections['detection_boxes'],\n",
    "                    detections['detection_classes']+label_id_offset,\n",
    "                    detections['detection_scores'],\n",
    "                    category_index_ssd,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    max_boxes_to_draw=10,\n",
    "                    min_score_thresh=threshold,\n",
    "                    agnostic_mode=False)\n",
    "\n",
    "        # print(detections)\n",
    "        #get data(label, xmin, ymin, xmax, ymax)\n",
    "  \n",
    "        output = []\n",
    "        for index, score in enumerate(detections['detection_scores']):\n",
    "            if score < threshold:\n",
    "                continue\n",
    "            label = category_index[detections['detection_classes'][index] + label_id_offset]['name']\n",
    "            # print(label)\n",
    "            ymin, xmin, ymax, xmax = detections['detection_boxes'][index]\n",
    "            output.append((label, int(xmin * image_width), int(ymin * image_height),\n",
    "                           int(xmax * image_width), int(ymax * image_height)))\n",
    "\n",
    "        # save incident \n",
    "        for l, x_min, y_min, x_max, y_max in output:\n",
    "            \n",
    "            # if l == \"NumberPlate\": #label_to_look_for\n",
    "            array = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "            image = Image.fromarray(array)\n",
    "            \n",
    "            cropped_img = image.crop((x_min, y_min, x_max, y_max))\n",
    "            # print(cropped_img.size)\n",
    "            # imgname = os.path.join('Tensorflow', 'workspace','images',f'{str(uuid.uuid1())}.jpg')\n",
    "            # cropped_img.save(imgname, 'JPEG', icc_profile=cropped_img.info.get('icc_profile'))\n",
    "            \n",
    "\n",
    "            input_ocr_image = image_resize_with_padding(cropped_img)\n",
    "            \n",
    "            ocr_predict(input_ocr_image,0.6)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # df.loc[len(df)] = [datetime.datetime.now(), file_path]\n",
    "            # df.to_csv(output_dir+'/results.csv', index=None)\n",
    "        \n",
    "        # # to save full images with bounding boxes\n",
    "        # cv2.imwrite(os.path.join('Tensorflow', 'workspace','images','results_new_test',jpg), image_np_with_detections)\n",
    "        \n",
    "        ## to plot images\n",
    "        # plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1431ac71-2d3e-4bd0-aff2-2a2abdba59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLU1BM5673\n",
      "KA04U5657\n",
      "KA41EN1051\n",
      "KL354199\n",
      "GJ03LK0563\n",
      "GJ01M7581\n",
      "KL65L2203\n",
      "6\n",
      "GJ07DA9988\n",
      "GJ23BM9629\n",
      "\n",
      "MH03CE9253\n",
      "N59A9Q1515\n",
      "DL10SZ3519\n",
      "UP54Z0690\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'test_images'\n",
    "predict(folder_path,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "39d75671-f3cd-4a6b-b039-d14d42c30414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K</td>\n",
       "      <td>168</td>\n",
       "      <td>162</td>\n",
       "      <td>225</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>233</td>\n",
       "      <td>165</td>\n",
       "      <td>280</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "      <td>168</td>\n",
       "      <td>375</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>387</td>\n",
       "      <td>169</td>\n",
       "      <td>427</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>156</td>\n",
       "      <td>283</td>\n",
       "      <td>203</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N</td>\n",
       "      <td>207</td>\n",
       "      <td>283</td>\n",
       "      <td>255</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>289</td>\n",
       "      <td>327</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>291</td>\n",
       "      <td>387</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>392</td>\n",
       "      <td>293</td>\n",
       "      <td>437</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>293</td>\n",
       "      <td>481</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  xmin  ymin  xmax  ymax\n",
       "2     K   168   162   225   250\n",
       "5     A   233   165   280   250\n",
       "4     4   317   168   375   256\n",
       "7     1   387   169   427   253\n",
       "0     E   156   283   203   357\n",
       "9     N   207   283   255   357\n",
       "8     1   298   289   327   362\n",
       "1     0   343   291   387   362\n",
       "3     5   392   293   437   365\n",
       "6     1   449   293   481   366"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_up = df[df.ymin < (df.ymin.min()*1.2)].sort_values(by  = ['xmin'])\n",
    "df_down = df[df.ymin > (df.ymin.min()*1.2)].sort_values(by  = ['xmin'])\n",
    "df1 = pd.concat([df_up,df_down])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc70bac-089d-4056-a29a-7b019917946a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
