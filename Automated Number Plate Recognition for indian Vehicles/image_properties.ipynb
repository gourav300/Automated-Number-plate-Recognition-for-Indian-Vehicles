{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd8aa39-e97e-4a62-9f16-b6dfc445b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "from pascal_voc_writer import Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346ed619-5457-4a92-b040-ecce89c4590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'workspace_path': os.path.join('Tensorflow', 'workspace'),\n",
    "    'scripts_path': os.path.join('Tensorflow','scripts'),\n",
    "    'apimodel_path': os.path.join('Tensorflow','models'),\n",
    "    'annotation_path': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'image_path': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'model_path': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'pretrained_model_path': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5869e0-b407-468d-9fb5-b82217ad2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = os.path.join('Tensorflow', 'workspace','images')\n",
    "train_folder_path = \"Tensorflow\\\\workspace\\\\images\\\\train\"\n",
    "validation_folder_path = \"Tensorflow\\\\workspace\\\\images\\\\validation\"\n",
    "test_folder_path = \"Tensorflow\\\\workspace\\\\images\\\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c6e589-c191-4bce-882e-ba47495c316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_train = os.listdir(train_folder_path)\n",
    "file_list_validation = os.listdir(validation_folder_path)\n",
    "file_list_test = os.listdir(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13caf36b-40bf-4993-8d93-a951064a3791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in Training folder :  879\n",
      "Total files in validation folder :  202\n",
      "Total files in Test folder :  294\n"
     ]
    }
   ],
   "source": [
    "print(\"Total files in Training folder : \", len(file_list_train))\n",
    "print(\"Total files in validation folder : \", len(file_list_validation))\n",
    "print(\"Total files in Test folder : \", len(file_list_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b304905-a6f4-4a21-a2d4-bb6aa5725d94",
   "metadata": {},
   "source": [
    "## Types of image formats in train and test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53a5c4b-b075-43cf-a533-b925bd283dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_train_extentions = [ext.split('.')[-1] for ext in file_list_train]\n",
    "file_list_validation_extentions = [ext.split('.')[-1] for ext in file_list_validation]\n",
    "file_list_test_extentions = [ext.split('.')[-1] for ext in file_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "328a3e9c-0bd0-4c3f-8f8a-b7099432c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['jpg' '408']\n",
      " ['xml' '408']]\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(folder_path)\n",
    "file_list_extentions = [ext.split('.')[-1] for ext in file_list]\n",
    "unique_ext(file_list_extentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8fb0915-b8ed-4725-862f-b68d871638dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique values and their counts\n",
    "def unique_ext(extensions_list):\n",
    "    x = np.array(extensions_list)\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9913aedf-fa02-4304-8e8e-951f4d46595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique extensions in training folder\n",
      "[['jpg' '439']\n",
      " ['xml' '440']]\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique extensions in training folder')\n",
    "unique_ext(file_list_train_extentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8990e622-6abe-4d0c-8ab5-2b687512a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique extensions in test folder\n",
      "[['jpg' '147']\n",
      " ['xml' '147']]\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique extensions in test folder')\n",
    "unique_ext(file_list_test_extentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8ec9b-2359-4dd1-84e3-d4cc91d129d7",
   "metadata": {},
   "source": [
    "## Convert jpeg/png files into jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc411df-c098-4527-ba26-20a73dda7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def jpeg_to_jpg(file_list,directory):\n",
    "    '''\n",
    "    Converts and save images of JPEG and PNG format to JPG.\n",
    "    Delete the JPEG and PNG format images\n",
    "    '''\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(directory)\n",
    "    count = 0    \n",
    "    for file in file_list:\n",
    "        file_name = file.split('.')[:-1]\n",
    "        file_name_str = '.'.join([str(elem) for elem in file_name])\n",
    "        file_name_jpg = file_name_str + '.jpg'\n",
    "        file_name_xml = file_name_str + '.xml'\n",
    "        file_ext = file.split('.')[-1]\n",
    "\n",
    "        if (file_ext == 'jpeg') | (file_ext == 'png'):\n",
    "\n",
    "            im = Image.open(file)\n",
    "            # print(\"The size of the image before conversion : \", end = \"\")\n",
    "            # print(os.path.getsize(file))\n",
    "\n",
    "            # converting to jpg\n",
    "            rgb_im = im.convert(\"RGB\")\n",
    "\n",
    "            # exporting the image\n",
    "            rgb_im.save(file_name_jpg)\n",
    "            os.remove(file)\n",
    "    \n",
    "            mytree = ET.parse(file_name_xml)\n",
    "            myroot = mytree.getroot()\n",
    "\n",
    "            # iterating through the name values.\n",
    "            \n",
    "            for names in myroot.iter('filename'):\n",
    "                # updates the name value\n",
    "                # if names.text.split('.')[1] == 'jpeg':\n",
    "                    \n",
    "                names.text = str(file_name_jpg)\n",
    "\n",
    "            \n",
    "            mytree.write(file_name_xml)\n",
    "            count+=1\n",
    "            # print(\"The size of the image after conversion : \", end = \"\")\n",
    "            # print(os.path.getsize(file_name))\n",
    "    print('Number of files converted : ', count)\n",
    "    os.chdir(cwd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d7beb2-1cd5-4da2-8532-5c0b438ac31a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Tensorflow\\\\workspace\\\\images\\\\temp_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mworkspace\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtemp_train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m file_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m jpeg_to_jpg(file_list,folder_path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Tensorflow\\\\workspace\\\\images\\\\temp_train'"
     ]
    }
   ],
   "source": [
    "folder_path = \"Tensorflow\\\\workspace\\\\images\\\\temp_valid\"\n",
    "file_list = os.listdir(folder_path)\n",
    "jpeg_to_jpg(file_list,folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9303e19b-7534-478b-93cb-bcbaccb5a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\gs\\\\Documents\\\\python\\\\anpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b0fbf6a-85e9-42d1-a648-d0476ad3067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files converted :  0\n"
     ]
    }
   ],
   "source": [
    "jpeg_to_jpg(file_list_train,train_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1033f6b8-6704-449e-a6a7-3ff1f3fb2231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files converted :  0\n"
     ]
    }
   ],
   "source": [
    "jpeg_to_jpg(file_list_test,test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36efaa7b-658c-431a-aa38-e1445f79cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\gs\\\\Documents\\\\python\\\\anpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a1a1ec-123f-415b-a938-9097950f108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_jpg_xml(file_list,directory):\n",
    "    '''\n",
    "    Converts and save images of JPEG and PNG format to JPG.\n",
    "    Delete the JPEG and PNG format images\n",
    "    '''\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(directory)\n",
    "    count = 0    \n",
    "    for file in file_list:\n",
    "        new_file_name = file.split('.')[0]\n",
    "        file_name = file.split('.')[:-1]\n",
    "        file_name_str = '.'.join([str(elem) for elem in file_name])\n",
    "        file_name_jpg = new_file_name + '.jpg'\n",
    "        file_name_xml = new_file_name + '.xml'\n",
    "        file_ext = file.split('.')[-1]\n",
    "\n",
    "        if (file_ext == 'jpg') | (file_ext == 'png'):\n",
    "\n",
    "            im = Image.open(file)\n",
    "            # print(\"The size of the image before conversion : \", end = \"\")\n",
    "            # print(os.path.getsize(file))\n",
    "\n",
    "            # converting to jpg\n",
    "            rgb_im = im.convert(\"RGB\")\n",
    "            \n",
    "            os.remove(file)\n",
    "\n",
    "            # exporting the image\n",
    "            rgb_im.save(file_name_jpg)\n",
    "            count+=1\n",
    "    \n",
    "            mytree = ET.parse(file_name_str + \".xml\")\n",
    "            myroot = mytree.getroot()\n",
    "\n",
    "            # iterating through the name values.\n",
    "            \n",
    "            for names in myroot.iter('filename'):\n",
    "                # updates the name value\n",
    "                # if names.text.split('.')[1] == 'jpeg':\n",
    "                    \n",
    "                names.text = str(file_name_jpg)\n",
    "\n",
    "            \n",
    "            os.remove(file_name_str + \".xml\")\n",
    "            mytree.write(file_name_xml)\n",
    "            count+=1\n",
    "            # print(\"The size of the image after conversion : \", end = \"\")\n",
    "            # print(os.path.getsize(file_name))\n",
    "    print('Number of files converted : ', count)\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73648019-4e95-4b2c-9974-21e5f5be575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files converted :  3750\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Tensorflow\\\\workspace\\\\images\\\\New folder\"\n",
    "file_list = os.listdir(folder_path)\n",
    "rename_jpg_xml(file_list,folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473496d1-1c71-4158-ab3a-e13869918aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9]\n",
    "k = 7\n",
    "count = len([i for i in a if i > k])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419364b4-b600-48da-a148-464ba7196489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d4f24f-d2ce-4255-9718-815a5515a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_size_in_folder(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    jpg_list = []\n",
    "    substring = '.jpg'\n",
    "    jpg_list = [string for string in file_list if substring in string]\n",
    "    height = []\n",
    "    width = []\n",
    "\n",
    "    for jpg in jpg_list:\n",
    "\n",
    "        xml_name = jpg.split('.')[0] + '.xml'\n",
    "        # print(jpg)\n",
    "\n",
    "        im = cv2.imread(os.path.join(folder_path,jpg))\n",
    "        # print(im)\n",
    "        height.append(im.shape[0])\n",
    "        width.append(im.shape[1])\n",
    "        # if (im.shape[0] >= 300) & (im.shape[0] <= 512):\n",
    "        #     print(jpg)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    print('Images size in folder path :\\\\', folder_path)\n",
    "    print('Number of images with height < 300pxl : ', len([i for i in height if i < 300]))\n",
    "    print('Number of images with height >= 300pxl and <= 512pxl : ', len([i for i in height if (i >= 300) & (i <= 512)]))\n",
    "    print('Number of images with height > 512pxl : ', len([i for i in height if i > 512]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877d6bd9-7ab2-44b5-8d5f-51c696fe29e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pth = os.path.join(train_folder_path,'img_512+')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# folder_path = r\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mimages_size_in_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_folder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mimages_size_in_folder\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path,jpg))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# print(im)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m height\u001b[38;5;241m.\u001b[39mappend(\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     17\u001b[0m width\u001b[38;5;241m.\u001b[39mappend(im\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# if (im.shape[0] >= 300) & (im.shape[0] <= 512):\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#     print(jpg)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# pth = os.path.join(train_folder_path,'img_512+')\n",
    "# folder_path = r\"\"\n",
    "images_size_in_folder(train_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec050d6-8f79-418d-9738-4974e0f20fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images size in folder path :\\ Tensorflow\\workspace\\images\\validation\n",
      "Number of images with height < 300pxl :  0\n",
      "Number of images with height >= 300pxl and <= 512pxl :  39\n",
      "Number of images with height > 512pxl :  62\n"
     ]
    }
   ],
   "source": [
    "images_size_in_folder(validation_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c92a892-9fcf-4176-8259-c8645da364a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images size in folder path :\\ Tensorflow\\workspace\\images\\test\n",
      "Number of images with height < 300pxl :  7\n",
      "Number of images with height >= 300pxl and <= 512pxl :  11\n",
      "Number of images with height > 512pxl :  132\n"
     ]
    }
   ],
   "source": [
    "images_size_in_folder(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9324dbda-060a-4607-b0d5-9766c4376679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_segregation_by_pxl(folder_path):\n",
    "    \n",
    "    file_list = [file for file in os.listdir(folder_path) \n",
    "         if os.path.isfile(os.path.join(folder_path, file))]\n",
    "    \n",
    "    jpg_list = []\n",
    "    substring = '.jpg'\n",
    "    jpg_list = [string for string in file_list if substring in string]\n",
    "    paths = {\n",
    "        'potrait' : os.path.join(folder_path,'potrait_images'),\n",
    "        'Img_512+' : os.path.join(folder_path,'img_512+'),\n",
    "        'Img_300_to_512' : os.path.join(folder_path,'img_300_to_512'),\n",
    "        'Img_300-' : os.path.join(folder_path,'img_300-')\n",
    "    }\n",
    "\n",
    "    for path in paths.values():\n",
    "        if not os.path.exists(path):\n",
    "            if os.name == 'posix':\n",
    "                !mkdir -p {path}\n",
    "            if os.name == 'nt':\n",
    "                !mkdir {path}\n",
    "                \n",
    "    \n",
    "    for jpg in jpg_list:\n",
    "        \n",
    "        xml_name = jpg.split('.')[0] + '.xml'\n",
    "\n",
    "        im = cv2.imread(os.path.join(folder_path,jpg))\n",
    "        height = im.shape[0]\n",
    "        width = im.shape[1]\n",
    "        existing_filepath_jpg = os.path.join(folder_path,jpg)\n",
    "        existing_filepath_xml = os.path.join(folder_path,xml_name)\n",
    "        \n",
    "        if (os.path.exists(existing_filepath_jpg)) & (os.path.exists(existing_filepath_xml)):\n",
    "            \n",
    "            # if width/height < 1:\n",
    "            #     new_filepath_jpg = os.path.join(paths['potrait'],jpg)\n",
    "            #     new_filepath_xml = os.path.join(paths['potrait'],xml_name)\n",
    "            #     os.replace(existing_filepath_jpg, new_filepath_jpg)\n",
    "            #     os.replace(existing_filepath_xml, new_filepath_xml)\n",
    "\n",
    "            if (height > 512) & (width > 512):\n",
    "\n",
    "                new_filepath_jpg = os.path.join(paths['Img_512+'],jpg)\n",
    "                new_filepath_xml = os.path.join(paths['Img_512+'],xml_name)\n",
    "                os.replace(existing_filepath_jpg, new_filepath_jpg)\n",
    "                os.replace(existing_filepath_xml, new_filepath_xml)\n",
    "\n",
    "            elif ((height >= 300) & (width >= 300)):\n",
    "                new_filepath_jpg = os.path.join(paths['Img_300_to_512'],jpg)\n",
    "                new_filepath_xml = os.path.join(paths['Img_300_to_512'],xml_name)\n",
    "                os.replace(existing_filepath_jpg, new_filepath_jpg)\n",
    "                os.replace(existing_filepath_xml, new_filepath_xml)\n",
    "\n",
    "            else:\n",
    "                new_filepath_jpg = os.path.join(paths['Img_300-'],jpg)\n",
    "                new_filepath_xml = os.path.join(paths['Img_300-'],xml_name)\n",
    "                os.replace(existing_filepath_jpg, new_filepath_jpg)\n",
    "                os.replace(existing_filepath_xml, new_filepath_xml)\n",
    "        \n",
    "    print('Transfer of files successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7d89823-7ed6-4407-b1f6-7e87f87dbf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer of files successful\n"
     ]
    }
   ],
   "source": [
    "image_file_segregation_by_pxl(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c98714e-7f7d-46e0-be5b-e14c596a8ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer of files successful\n"
     ]
    }
   ],
   "source": [
    "image_file_segregation_by_pxl(validation_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdf9240-1472-4c80-8050-c8bdcbb9a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer of files successful\n"
     ]
    }
   ],
   "source": [
    "image_file_segregation_by_pxl(train_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a597d78-c004-49b0-a4de-a109ef2716fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a15c647-c7d4-46b8-9101-f52933352e87",
   "metadata": {},
   "source": [
    "## 2. Image Augmentation using Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "560f208a-7835-4ecd-b347-1f599e6cd2e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "     ------------------------------------ 102.4/102.4 kB 591.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\pyyaml-5.4.1-py3.9-win-amd64.egg (from albumentations) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.19.2-cp39-cp39-win_amd64.whl (12.6 MB)\n",
      "     -------------------------------------- 12.6/12.6 MB 719.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages (from albumentations) (1.22.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\scipy-1.8.0-py3.9-win-amd64.egg (from albumentations) (1.8.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\opencv_python_headless-4.5.5.64-py3.9-win-amd64.egg (from albumentations) (4.5.5.64)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\scikit_learn-1.1.0-py3.9-win-amd64.egg (from qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.2.0)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.19.2-py3-none-any.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 931.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\pillow-9.1.0-py3.9-win-amd64.egg (from scikit-image>=0.16.1->albumentations) (9.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.5.4-py3-none-any.whl (195 kB)\n",
      "     -------------------------------------- 195.6/195.6 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-2.8-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\joblib-1.1.0-py3.9.egg (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gs\\documents\\environments\\tfod\\lib\\site-packages\\threadpoolctl-3.1.0-py3.9.egg (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Installing collected packages: tifffile, PyWavelets, networkx, imageio, scikit-image, qudida, albumentations\n",
      "Successfully installed PyWavelets-1.3.0 albumentations-1.1.0 imageio-2.19.2 networkx-2.8 qudida-0.0.4 scikit-image-0.19.2 tifffile-2022.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2544ba6-6352-49e5-8baa-9f6b38b04eff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pascal-voc-writer\n",
      "  Downloading pascal_voc_writer-0.1.4-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Installing collected packages: MarkupSafe, jinja2, pascal-voc-writer\n",
      "Successfully installed MarkupSafe-2.1.1 jinja2-3.1.2 pascal-voc-writer-0.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pascal-voc-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a8e2f8-6484-42c6-8e35-df9dab322e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "from pascal_voc_writer import Writer\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e64698b-9933-4f69-8e8d-49ad9c6fcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=512, height=512),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.RandomGamma(p=0.2), \n",
    "    A.RGBShift(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.3, label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b653010-2ef8-453f-b6bf-6cae5f806fb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def albumentation_pipeline(source_file_path,destination_file_path,num_images):\n",
    "    \n",
    "    file_list = [file for file in os.listdir(source_file_path) \n",
    "             if os.path.isfile(os.path.join(source_file_path, file))]\n",
    "    # file_list = os.listdir(source_file_path)\n",
    "    print('Number of images : ',len(file_list)//2)\n",
    "    blank_file_count = 0\n",
    "    file_count = 0\n",
    "    for file in file_list:\n",
    "\n",
    "        file_name = file.split('.')[0]\n",
    "        file_ext = file.split('.')[1]\n",
    "\n",
    "        if (file_ext == 'jpg'):\n",
    "            # print((os.path.join(source_file_path,file_name,f'.jpg'))\n",
    "            img = cv2.imread(os.path.join(source_file_path,f'{file_name}.jpg'))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "            xml_file_address = os.path.join(source_file_path,f'{file_name}.xml')\n",
    "            mytree = ET.parse(xml_file_address)\n",
    "\n",
    "            myroot = mytree.getroot()\n",
    "\n",
    "            # iterating through the bndbox values.\n",
    "            bbox = []\n",
    "            class_label = []\n",
    "            for box in myroot.iter('bndbox'):\n",
    "                bbox_temp = []\n",
    "                bbox_temp.append(int(box.find('xmin').text))\n",
    "                bbox_temp.append(int(box.find('ymin').text))\n",
    "                bbox_temp.append(int(box.find('xmax').text))\n",
    "                bbox_temp.append(int(box.find('ymax').text))\n",
    "                bbox_temp.append('NumberPlate')\n",
    "                bbox.append(bbox_temp)\n",
    "                class_label.append('NumberPlate')\n",
    "\n",
    "            # print(bbox)\n",
    "\n",
    "            for num_img in range(num_images):\n",
    "                transformed = transform(image=img, bboxes=bbox, class_labels = class_label)\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_bboxes = transformed['bboxes']\n",
    "                # transformed_class_labels = transformed['class_labels']\n",
    "                if ((len(transformed_bboxes) == 0) & (blank_file_count < (len(file_list)*.50))) | (len(transformed_bboxes) != 0):\n",
    "\n",
    "                    \n",
    "                    cv2.imwrite(os.path.join(destination_file_path, f'{file_name}_{num_img}.jpg' ), transformed_image)\n",
    "                    # create pascal voc writer (image_path, width, height)\n",
    "                    # print(transformed_image.shape)\n",
    "                    writer = Writer(os.path.join(destination_file_path, f'{file_name}_{num_img}.jpg'), \n",
    "                                    transformed_image.shape[1], transformed_image.shape[0])\n",
    "                    # add objects (class, xmin, ymin, xmax, ymax)\n",
    "                    for info in (transformed_bboxes):\n",
    "                        writer.addObject(info[4], round(info[0]), round(info[1]), round(info[2]), round(info[3]))\n",
    "                    # write to file\n",
    "                    writer.save(os.path.join(destination_file_path, f'{file_name}_{num_img}.xml'))\n",
    "                    blank_file_count+=1\n",
    "                    file_count+=1\n",
    "                    # print(transformed_bboxes)\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "    print('Total number of augmented images : ', file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a09c17b0-0163-497e-bbd7-1d8174ba3c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  260\n",
      "Total number of augmented images :  3139\n"
     ]
    }
   ],
   "source": [
    "source_file_path = os.path.join(paths['image_path'],'train', 'img_512+')\n",
    "destination_file_path = os.path.join(paths['image_path'],'train','img_512+','aug')\n",
    "num_images = 20\n",
    "albumentation_pipeline(source_file_path,destination_file_path,num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18e9022c-e9c0-44ad-9037-ef246bcc8ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  62\n",
      "Total number of augmented images :  780\n"
     ]
    }
   ],
   "source": [
    "source_file_path = os.path.join(paths['image_path'],'validation', 'img_512+')\n",
    "destination_file_path = os.path.join(paths['image_path'],'validation','img_512+','aug')\n",
    "num_images = 20\n",
    "albumentation_pipeline(source_file_path,destination_file_path,num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ae6004-0ed5-4225-9a2c-6054cad2b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  96\n",
      "Total number of augmented images :  744\n"
     ]
    }
   ],
   "source": [
    "source_file_path = os.path.join(paths['image_path'],'test', 'img_512+')\n",
    "destination_file_path = os.path.join(paths['image_path'],'test','img_512+','aug')\n",
    "num_images = 15\n",
    "albumentation_pipeline(source_file_path,destination_file_path,num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c1340b5-e65c-4ba5-be73-38d7cb9a1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=300, height=300),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.RandomGamma(p=0.2), \n",
    "    A.RGBShift(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.3, label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9423558d-45d4-4bfd-b9c5-36b6a7386ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  179\n",
      "Total number of augmented images :  3313\n"
     ]
    }
   ],
   "source": [
    "source_file_path = os.path.join(paths['image_path'],'train', 'img_300_to_512')\n",
    "destination_file_path = os.path.join(paths['image_path'],'train','img_300_to_512','aug')\n",
    "num_images = 20\n",
    "albumentation_pipeline(source_file_path,destination_file_path,num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9573169-359c-47ec-a8e6-b15eccf9e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  39\n",
      "Total number of augmented images :  641\n"
     ]
    }
   ],
   "source": [
    "source_file_path = os.path.join(paths['image_path'],'validation', 'img_300_to_512')\n",
    "destination_file_path = os.path.join(paths['image_path'],'validation','img_300_to_512','aug')\n",
    "num_images = 20\n",
    "albumentation_pipeline(source_file_path,destination_file_path,num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b20f8b76-c202-4286-8203-358b650f9586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  41\n",
      "Total number of augmented images :  502\n"
     ]
    }
   ],
   "source": [
    "source_file_path = os.path.join(paths['image_path'],'test', 'img_300_to_512')\n",
    "destination_file_path = os.path.join(paths['image_path'],'test','img_300_to_512','aug')\n",
    "num_images = 15\n",
    "albumentation_pipeline(source_file_path,destination_file_path,num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7e8bb-240c-4383-95cc-d4c3f77a3102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e16901e-8689-456b-b80d-fbdf580b90e2",
   "metadata": {},
   "source": [
    "## resizing images alongwith annotations while maintaining aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83731a21-1bc3-4642-8b09-b749f9a78c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = \"Tensorflow/workspace/images/resize/License (25).png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1fc885c-1a9b-487b-afbe-3aabe38eeba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ab2038-c2a4-49cc-b8a5-0f6dcc664ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_height,new_width) = im.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4481ef-bba7-4336-85b9-89f5a2d333c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape[:2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848157c7-d1a2-4fec-9566-47547ab3fe92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3eddb0-a998-45a6-8b19-ae60e6336954",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [file for file in os.listdir(source_file_path) \n",
    "             if os.path.isfile(os.path.join(source_file_path, file))]\n",
    "    # file_list = os.listdir(source_file_path)\n",
    "    print('Number of images : ',len(file_list)//2)\n",
    "    # blank_file_count = 0\n",
    "    # file_count = 0\n",
    "    for file in file_list:\n",
    "\n",
    "        file_name = file.split('.')[0]\n",
    "        file_ext = file.split('.')[1]\n",
    "\n",
    "        if (file_ext == 'png'):\n",
    "            # print((os.path.join(source_file_path,file_name,f'.jpg'))\n",
    "            img = cv2.imread(os.path.join(source_file_path,f'{file_name}.png'))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "            xml_file_address = os.path.join(source_file_path,f'{file_name}.xml')\n",
    "            xml_list =[]\n",
    "            tree = ET.parse(xml_file_address)\n",
    "            root = tree.getroot()\n",
    "            for member in root.findall('object'):\n",
    "                value = (root.find('filename').text,\n",
    "                         int(root.find('size')[0].text),\n",
    "                         int(root.find('size')[1].text),\n",
    "                         member[0].text,\n",
    "                         int(member[4].find('xmin').text),\n",
    "                         int(member[4].find('ymin').text),\n",
    "                         int(member[4].find('xmax').text),\n",
    "                         int(member[4].find('ymax').text)\n",
    "                         )\n",
    "                xml_list.append(value)\n",
    "                    \n",
    "                cv2.imwrite(os.path.join(destination_file_path, f'{file_name}.jpg' ), transformed_image)\n",
    "                # create pascal voc writer (image_path, width, height)\n",
    "                # print(transformed_image.shape)\n",
    "                writer = Writer(os.path.join(destination_file_path, f'{file_name}.jpg'), \n",
    "                                transformed_image.shape[1], transformed_image.shape[0])\n",
    "                # add objects (class, xmin, ymin, xmax, ymax)\n",
    "                for info in (transformed_bboxes):\n",
    "                    writer.addObject(info[4], round(info[0]), round(info[1]), round(info[2]), round(info[3]))\n",
    "                # write to file\n",
    "                writer.save(os.path.join(destination_file_path, f'{file_name}.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb3e773d-c759-426f-859d-cd39f81336f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(source_file_path, destination_file_path , desired_size, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    file_list = [file for file in os.listdir(source_file_path) \n",
    "             if os.path.isfile(os.path.join(source_file_path, file))]\n",
    "    # file_list = os.listdir(source_file_path)\n",
    "    print('Number of images : ',len(file_list)//2)\n",
    "    # blank_file_count = 0\n",
    "    # file_count = 0\n",
    "    for file in file_list:\n",
    "\n",
    "        file_name = file.split('.')[0]\n",
    "        file_ext = file.split('.')[1]\n",
    "\n",
    "        if ((file_ext == 'png') | (file_ext == 'jpg')):\n",
    "            # print((os.path.join(source_file_path,file_name,f'.jpg'))\n",
    "            image = cv2.imread(os.path.join(source_file_path,f'{file}'))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "            xml_file_address = os.path.join(source_file_path,f'{file_name}.xml')\n",
    "            \n",
    "            xml_list =[]\n",
    "            tree = ET.parse(xml_file_address)\n",
    "            root = tree.getroot()\n",
    "            for member in root.findall('object'):\n",
    "                value = (root.find('filename').text,\n",
    "                         int(root.find('size')[0].text),\n",
    "                         int(root.find('size')[1].text),\n",
    "                         member[0].text,\n",
    "                         int(member[4].find('xmin').text),\n",
    "                         int(member[4].find('ymin').text),\n",
    "                         int(member[4].find('xmax').text),\n",
    "                         int(member[4].find('ymax').text)\n",
    "                         )\n",
    "                xml_list.append(value)\n",
    "            old_size = image.shape[:2]\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "            \n",
    "#             dim = None\n",
    "            \n",
    "\n",
    "#             # if both the width and height are None, then return the\n",
    "#             # original image\n",
    "#             if width is None and height is None:\n",
    "#                 return image\n",
    "\n",
    "#             # check to see if the width is None\n",
    "#             if width is None:\n",
    "#                 # calculate the ratio of the height and construct the\n",
    "#                 # dimensions\n",
    "#                 r = height / float(h)\n",
    "#                 dim = (int(w * r), height)\n",
    "\n",
    "#             # otherwise, the height is None\n",
    "#             else:\n",
    "#                 # calculate the ratio of the width and construct the\n",
    "#                 # dimensions\n",
    "#                 r = width / float(w)\n",
    "#                 dim = (width, int(h * r))\n",
    "\n",
    "            # resize the image\n",
    "            resized = cv2.resize(image, (new_size[1],new_size[0]))\n",
    "\n",
    "            # new_size = resized.shape[:2]\n",
    "            # print(new_size)\n",
    "            # delta_w = resized.shape[:2][1] -  image.shape[:2][1]\n",
    "            # delta_h = resized.shape[:2][0] -  image/shape[:2][0]\n",
    "\n",
    "            delta_w = desired_size - new_size[1]\n",
    "            delta_h = desired_size - new_size[0]\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "            # print(top,bottom,left,right)\n",
    "\n",
    "            color = [255, 255, 255]\n",
    "            new_im = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "            cv2.imwrite(os.path.join(destination_file_path, f'{file}' ), new_im)\n",
    "            \n",
    "            writer = Writer(os.path.join(destination_file_path, f'{file}'), \n",
    "                                new_im.shape[1], new_im.shape[0])\n",
    "            # add objects (class, xmin, ymin, xmax, ymax)\n",
    "            for info in (xml_list):\n",
    "                writer.addObject(info[3], round(info[4]*ratio + left), round(info[5]*ratio + bottom), round(info[6]*ratio + right), round(info[7]*ratio + top))\n",
    "            # write to file\n",
    "            writer.save(os.path.join(destination_file_path, f'{file_name}.xml'))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # return the resized image\n",
    "    # return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351b7f00-6730-4e3e-b5bc-3bca0a9a00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_path = os.path.join('number_plate_digit_dataset')\n",
    "destination_file_path = os.path.join('data_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12511b49-46cb-40a0-b4e2-840d8d8b26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images :  3627\n"
     ]
    }
   ],
   "source": [
    "image_resize(source_file_path,destination_file_path,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48cf76be-404e-488b-a7d4-92db2074ea57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad241063-ce26-4a3a-820c-2d43c357d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = \"Tensorflow/workspace/images/resize/License (25).xml\"\n",
    "xml_list =[]\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "for member in root.findall('object'):\n",
    "    value = (root.find('filename').text,\n",
    "             int(root.find('size')[0].text),\n",
    "             int(root.find('size')[1].text),\n",
    "             member[0].text,\n",
    "             int(member[4].find('xmin').text),\n",
    "             int(member[4].find('ymin').text),\n",
    "             int(member[4].find('xmax').text),\n",
    "             int(member[4].find('ymax').text)\n",
    "             )\n",
    "    xml_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45558028-41a2-4a90-85d3-560f1b6afc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('License (25).png', 128, 36, 'W', 14, 7, 23, 25),\n",
       " ('License (25).png', 128, 36, 'B', 26, 7, 34, 25),\n",
       " ('License (25).png', 128, 36, '0', 37, 8, 45, 25),\n",
       " ('License (25).png', 128, 36, '2', 48, 8, 57, 25),\n",
       " ('License (25).png', 128, 36, 'A', 58, 7, 67, 25),\n",
       " ('License (25).png', 128, 36, 'A', 69, 8, 77, 25),\n",
       " ('License (25).png', 128, 36, '3', 80, 8, 89, 25),\n",
       " ('License (25).png', 128, 36, '5', 91, 8, 100, 25),\n",
       " ('License (25).png', 128, 36, '7', 101, 8, 110, 25),\n",
       " ('License (25).png', 128, 36, '2', 113, 8, 122, 25)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "603ae101-0372-4278-827a-f91a8b36bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('License (25).png', 128, 36, 'B', 26, 7, 34, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5c01e96-8d0c-439a-bbe1-ccf5d0f8b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    " for info in (xml_list):\n",
    "        print(info[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721126c-a3a3-447a-9496-ffd6a618b6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
